{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diplodatos Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present this peace of code to create the baseline for the competition, and as an example of how to deal with these kind of problems. The main goals are that you:\n",
    "\n",
    "1. Learn\n",
    "1. Try different models and see which one fits the best the given data\n",
    "1. Get a higher score than the given one in the current baseline example\n",
    "1. Try to get the highest score in the class :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the given labels\n",
    "breed = pd.read_csv('../data/breed_labels.csv')\n",
    "color = pd.read_csv('../data/color_labels.csv')\n",
    "state = pd.read_csv('../data/state_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we take a look at the labels, just to understand what these are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#breed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#breed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we are ready to deal with the *original* dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_df = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to transform the datasets. This is done by means of a function so that the transformations are the same for the training and testing datasets... We replace the encodings just to make it easy to \"visualize\" the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(train_data_fname, test_data_fname):\n",
    "    def transform_columns(df):\n",
    "        df = df.drop([\"Description\"], axis=1)\n",
    "        df.Type = df.Type.replace({1: 'Dog', 2: 'Cat'})\n",
    "        df.Gender = df.Gender.replace({1:'Male', 2:'Female', 3:'Mixed'})\n",
    "        df.MaturitySize = df.MaturitySize.replace({1:'S', 2:'M', 3:'L', 4:'XL', 0:'N/A'})\n",
    "        df.FurLength = df.FurLength.replace({1:'S', 2:'M', 3:'L', 0:'N/A'})\n",
    "        df.Vaccinated = df.Vaccinated.replace({1:'T', 2:'N', 3:'N/A'})\n",
    "        df.Dewormed = df.Dewormed.replace({1:'T', 2:'F', 3:'N/A'})\n",
    "        df.Sterilized = df.Sterilized.replace({1:'T', 2:'F', 3:'N/A'})\n",
    "        df.Health = df.Health.replace({1:'Healthy', 2: 'MinorInjury', 3:'SeriousInjury', 0: 'N/A'})\n",
    "        df.Color1 = df.Color1.replace(dict(list(zip(color.ColorID, color.ColorName)) + [(0, \"N/A\")]))\n",
    "        df.Color2 = df.Color2.replace(dict(list(zip(color.ColorID, color.ColorName)) + [(0, \"N/A\")]))\n",
    "        df.Color3 = df.Color3.replace(dict(list(zip(color.ColorID, color.ColorName)) + [(0, \"N/A\")]))\n",
    "        df.Breed1 = df.Breed1.replace(dict(list(zip(breed.BreedID, breed.BreedName)) + [(0, \"N/A\")]))\n",
    "        df.Breed2 = df.Breed2.replace(dict(list(zip(breed.BreedID, breed.BreedName)) + [(0, \"N/A\")]))\n",
    "        return df\n",
    "    \n",
    "    df_train = pd.read_csv(train_data_fname)\n",
    "    df_train = transform_columns(df_train)\n",
    "    df_test = pd.read_csv(test_data_fname)\n",
    "    df_test = transform_columns(df_test)\n",
    "    \n",
    "    df = pd.concat([df_train, df_test], sort=True)\n",
    "\n",
    "    # set dummy variables for everything\n",
    "    # except from Age, Quantity, Fee\n",
    "    df = pd.get_dummies(df)\n",
    "    # get train and test back\n",
    "    n = len(df_train)\n",
    "    df_train = df.iloc[:n]\n",
    "    df_test = df.iloc[n:]\n",
    "    \n",
    "    y = df_train['AdoptionSpeed']\n",
    "    X = df_train.drop('AdoptionSpeed', axis=1)\n",
    "    yy = None\n",
    "    XX = df_test.drop('AdoptionSpeed', axis=1)\n",
    "\n",
    "    return X, y, XX, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.get_dummies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, y, XX, yy = transform_data(\"../data/train.csv\", \"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training dataset into train and \"validation\" \n",
    "# (we won't be using validation set in this example, because of the cross-validation;\n",
    "# but it couldn be useful for you depending on your approach)\n",
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "#X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "#results = pd.DataFrame(columns=('clf', 'best_acc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train[\"PID\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_petts(classifier, exploring_params, X_train, X_valid, y_train, y_valid, results):\n",
    "    \n",
    "    model = GridSearchCV(classifier, exploring_params, scoring='accuracy', cv=3, iid=False , n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    best_model_clf = model.best_estimator_\n",
    "    print(\"=\"*100)\n",
    "    print('Best clasifier accuracy: ', model.best_score_)\n",
    "    print(best_model_clf)\n",
    "    results = results.append({'clf': best_model_clf, 'best_acc': model.best_score_}, ignore_index=True)\n",
    "\n",
    "    print('The best classifier so far is: ')\n",
    "    print(results.loc[results['best_acc'].idxmax()]['clf'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#exploring_params = {'criterion':('gini', 'entropy'), 'min_samples_leaf':(1, 2, 5),\n",
    "#              'min_samples_split':(2, 3, 5, 10, 50, 100)}\n",
    "#classifier = DecisionTreeClassifier(random_state=42)\n",
    "#X_train = X_train.drop([\"PID\"], axis=1)\n",
    "#results = predict_petts(classifier, exploring_params, X_train, X_valid, y_train, y_valid, results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And finally**, we predict the unknown label for the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.shape, XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yy = results.clf.iloc[0].predict(XX.drop([\"PID\"], axis=1))\n",
    "#yy = yy.astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we do is generating a file that should be *submitted* on kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission = pd.DataFrame(list(zip(XX.PID, yy)), columns=[\"PID\", \"AdoptionSpeed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission.to_csv(\"../data/submission.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRADIENT DESCENT : LOGISTIC REGRESSION / PERCEPTRON / SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import SGDClassifier\n",
    "#for idx, loss in enumerate(('hinge', 'log', 'perceptron'), start=1):\n",
    "#    exploring_params = {\n",
    "#        'learning_rate': ['constant'],\n",
    "#        'eta0': [0.1, 0.01, 0.001] ,  # Tasa de entrenamiento\n",
    "#        'alpha': [0.1, 0.01, 0.001]  # Tasa de regularización\n",
    "#    }\n",
    "#    classifier = SGDClassifier(loss=loss, tol=1e-3, penalty='l2')\n",
    "#    results = predict_petts(classifier, exploring_params, X_train, X_valid, y_train, y_valid, results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Best clasifier accuracy:  0.3699181706307913\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l1', random_state=0, solver='warn',\n",
      "          tol=0.001, verbose=0, warm_start=False)\n",
      "The best classifier so far is: \n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l1', random_state=0, solver='warn',\n",
      "          tol=0.001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisvargas/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/luisvargas/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X2, y2, XX2, yy2 = transform_data(\"../data/train.csv\", \"../data/test.csv\")\n",
    "random_state=0\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3, random_state=random_state) \n",
    "results2 = pd.DataFrame(columns=('clf', 'best_acc'))\n",
    "\n",
    "# Fitting Logistic Regression To the training set \n",
    "from sklearn.linear_model import LogisticRegression   \n",
    "  \n",
    "classifier2 = LogisticRegression(random_state=random_state, fit_intercept=True) \n",
    "\n",
    "exploring_params2 = {\n",
    "        #'penalty': ['l1'],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        #'tol': [1e-3],\n",
    "        'tol': [1e-3, 1e-2, 1e-1],\n",
    "        #'C': [0.1],\n",
    "        'C': [1, 0.1, 0.01, 0.0001]\n",
    "    }\n",
    "X_train2 = X_train2.drop([\"PID\"], axis=1)\n",
    "results2 = predict_petts(classifier2, exploring_params2, X_train2, X_test2, y_train2, y_test2, results2)\n",
    "\n",
    "yy2 = results2.clf.iloc[0].predict(XX2.drop([\"PID\"], axis=1))\n",
    "yy2 = yy2.astype(np.int)\n",
    "\n",
    "submission2 = pd.DataFrame(list(zip(XX2.PID, yy2)), columns=[\"PID\", \"AdoptionSpeed\"])\n",
    "submission2.to_csv(\"../data/submission4.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PERCEPTRON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Best clasifier accuracy:  0.27582207522190993\n",
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "      fit_intercept=True, max_iter=None, n_iter=None, n_iter_no_change=5,\n",
      "      n_jobs=None, penalty=None, random_state=0, shuffle=True, tol=None,\n",
      "      validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "The best classifier so far is: \n",
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "      fit_intercept=True, max_iter=None, n_iter=None, n_iter_no_change=5,\n",
      "      n_jobs=None, penalty=None, random_state=0, shuffle=True, tol=None,\n",
      "      validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisvargas/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X2, y2, XX2, yy2 = transform_data(\"../data/train.csv\", \"../data/test.csv\")\n",
    "random_state=0\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3, random_state=random_state) \n",
    "results2 = pd.DataFrame(columns=('clf', 'best_acc'))\n",
    "\n",
    "# Fitting Logistic Regression To the training set \n",
    "from sklearn.linear_model import Perceptron   \n",
    "  \n",
    "classifier2 = Perceptron(random_state=random_state, fit_intercept=True) \n",
    "\n",
    "exploring_params2 = {\n",
    "        #'penalty': ['l1'],\n",
    "        #'penalty': ['l1', 'l2'],\n",
    "        #'tol': [1e-3],\n",
    "        #'tol': [1e-3, 1e-2, 1e-1],\n",
    "        #'C': [0.1],\n",
    "        #'C': [1, 0.1, 0.01, 0.0001]\n",
    "    }\n",
    "X_train2 = X_train2.drop([\"PID\"], axis=1)\n",
    "results2 = predict_petts(classifier2, exploring_params2, X_train2, X_test2, y_train2, y_test2, results2)\n",
    "\n",
    "yy2 = results2.clf.iloc[0].predict(XX2.drop([\"PID\"], axis=1))\n",
    "yy2 = yy2.astype(np.int)\n",
    "\n",
    "submission2 = pd.DataFrame(list(zip(XX2.PID, yy2)), columns=[\"PID\", \"AdoptionSpeed\"])\n",
    "submission2.to_csv(\"../data/submission3.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Best clasifier accuracy:  0.3226493567464566\n",
      "LinearSVC(C=0.4, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "     verbose=0)\n",
      "The best classifier so far is: \n",
      "LinearSVC(C=0.4, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "     verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisvargas/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "X2, y2, XX2, yy2 = transform_data(\"../data/train.csv\", \"../data/test.csv\")\n",
    "random_state=0\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3, random_state=random_state) \n",
    "results2 = pd.DataFrame(columns=('clf', 'best_acc'))\n",
    "\n",
    "# Fitting Logistic Regression To the training set \n",
    "from sklearn.svm import LinearSVC\n",
    "  \n",
    "classifier2 = LinearSVC() \n",
    "\n",
    "exploring_params2 = {\n",
    "        #'penalty': ['l1'],\n",
    "        'penalty': ['l2'],\n",
    "        #'tol': [1e-3],\n",
    "        'tol': [1e-3, 1e-2, 1e-1, 10],\n",
    "        #'C': [0.4],\n",
    "        'C': [1, 0.4, 0.1, 0.01,]\n",
    "    }\n",
    "X_train2 = X_train2.drop([\"PID\"], axis=1)\n",
    "results2 = predict_petts(classifier2, exploring_params2, X_train2, X_test2, y_train2, y_test2, results2)\n",
    "\n",
    "yy2 = results2.clf.iloc[0].predict(XX2.drop([\"PID\"], axis=1))\n",
    "yy2 = yy2.astype(np.int)\n",
    "\n",
    "submission2 = pd.DataFrame(list(zip(XX2.PID, yy2)), columns=[\"PID\", \"AdoptionSpeed\"])\n",
    "submission2.to_csv(\"../data/submission3.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression  + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisvargas/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/luisvargas/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/luisvargas/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Best clasifier accuracy:  0.2980936180308626\n",
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l1', random_state=0, solver='warn',\n",
      "          tol=0.001, verbose=0, warm_start=False)\n",
      "The best classifier so far is: \n",
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l1', random_state=0, solver='warn',\n",
      "          tol=0.001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisvargas/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/luisvargas/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 359 features per sample; expecting 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-76c253f5b3e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_petts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexploring_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 262\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 359 features per sample; expecting 2"
     ]
    }
   ],
   "source": [
    "X, y, XX, yy = transform_data(\"../data/train.csv\", \"../data/test.csv\")\n",
    "random_state=0\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state) \n",
    "results = pd.DataFrame(columns=('clf', 'best_acc'))\n",
    "\n",
    "# Fitting Logistic Regression To the training set \n",
    "from sklearn.linear_model import LogisticRegression   \n",
    "  \n",
    "    \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "sc = StandardScaler() \n",
    "  \n",
    "X_train = sc.fit_transform(X_train) \n",
    "X_test = sc.transform(X_test) \n",
    "\n",
    "# performing preprocessing part \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "sc = StandardScaler()\n",
    "  \n",
    "X_train = sc.fit_transform(X_train) \n",
    "X_test = sc.transform(X_test)  \n",
    "\n",
    "\n",
    "# Applying PCA function on training \n",
    "# and testing set of X component \n",
    "from sklearn.decomposition import PCA \n",
    "  \n",
    "pca = PCA(n_components=2) \n",
    "  \n",
    "X_train = pca.fit_transform(X_train) \n",
    "X_test = pca.transform(X_test) \n",
    "  \n",
    "explained_variance = pca.explained_variance_ratio_ \n",
    "\n",
    "    \n",
    "classifier = LogisticRegression(random_state=random_state, fit_intercept=True) \n",
    "\n",
    "exploring_params = {\n",
    "        #'penalty': ['l1'],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        #'tol': [1e-3],\n",
    "        'tol': [1e-3, 1e-2, 1e-1],\n",
    "        #'C': [0.1],\n",
    "        'C': [1, 0.1, 0.01, 0.0001]\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame({'PC1':X_train[:,0],'PC2':X_train[:,1]})\n",
    "results = predict_petts(classifier, exploring_params, X_train, X_test, y_train, y_test, results)\n",
    "\n",
    "yy = results.clf.iloc[0].predict(XX.drop([\"PID\"], axis=1))\n",
    "yy = yy.astype(np.int)\n",
    "\n",
    "submission = pd.DataFrame(list(zip(XX.PID, yy)), columns=[\"PID\", \"AdoptionSpeed\"])\n",
    "submission.to_csv(\"../data/submission3.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_set, y_set = X_train, y_train\n",
    "X_set.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "sc = StandardScaler() \n",
    "  \n",
    "X_train = sc.fit_transform(X_train) \n",
    "X_test = sc.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing preprocessing part \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "sc = StandardScaler()\n",
    "  \n",
    "X_train = sc.fit_transform(X_train) \n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying PCA function on training \n",
    "# and testing set of X component \n",
    "from sklearn.decomposition import PCA \n",
    "  \n",
    "pca = PCA(n_components = 2) \n",
    "  \n",
    "X_train = pca.fit_transform(X_train) \n",
    "X_test = pca.transform(X_test) \n",
    "  \n",
    "explained_variance = pca.explained_variance_ratio_ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Logistic Regression To the training set \n",
    "from sklearn.linear_model import LogisticRegression   \n",
    "  \n",
    "classifier = LogisticRegression(random_state = 0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploring_params = {\n",
    "        'penalty': ['l1','l2'],\n",
    "        'tol': [1e-3, 1e-2, 1e-1],\n",
    "        'C': [170 ,150, 140, 10]\n",
    "    }\n",
    "results = predict_petts(classifier, exploring_params, X_train, X_test, y_train, y_test, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test set result using  \n",
    "# predict function under LogisticRegression  \n",
    "y_pred = classifier.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making confusion matrix between \n",
    "#  test set of Y and predicted value. \n",
    "from sklearn.metrics import confusion_matrix \n",
    "  \n",
    "cm = confusion_matrix(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_set, y_set = X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, \n",
    "                     stop = X_set[:, 0].max() + 1, step = 0.01), \n",
    "                     np.arange(start = X_set[:, 1].min() - 1, \n",
    "                     stop = X_set[:, 1].max() + 1, step = 0.01)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Predicting the training set \n",
    "# result through scatter plot  \n",
    "from matplotlib.colors import ListedColormap \n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), \n",
    "             X2.ravel()]).T).reshape(X1.shape), alpha = 0.75, \n",
    "             cmap = ListedColormap(('yellow', 'white', 'aquamarine'))) \n",
    "  \n",
    "plt.xlim(X1.min(), X1.max()) \n",
    "plt.ylim(X2.min(), X2.max()) \n",
    "  \n",
    "for i, j in enumerate(np.unique(y_set)): \n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], \n",
    "                c = ListedColormap(('red', 'green', 'blue'))(i), label = j) \n",
    "  \n",
    "plt.title('Logistic Regression (Training set)') \n",
    "plt.xlabel('PC1') # for Xlabel \n",
    "plt.ylabel('PC2') # for Ylabel \n",
    "plt.legend() # to show legend \n",
    "  \n",
    "# show scatter plot \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
