---
title: "Entrega"
output: html_document
---

## Ejercicios:

Visualizacion es una herramienta muy importante para la generacion de intuicion, pero
raramente uno tiene los datos en la forma necesaria. Frecuentemente se necesitara 
crear nuevas variables o simplemente reordenarlas.

Exploraremos ahora la manipulacion basica utilizando un conjunto de datos sobre los
vuelos en Nueva York en 2013.

```{r echo=TRUE}
library(nycflights13)
fligths<-nycflights13::flights
```

***
## Practico 1: Entregar un Rmd donde se encuentren todos los vuelos que:

- Que arribaron con un retraso de mas de dos horas.
```{r echo=TRUE}
fligths_delay_2 <- fligths[fligths$dep_delay > 2,]
```

- Volaron hacia Houston (IAH o HOU)
```{r echo=TRUE}
fligths_houston <- fligths[(fligths$dest == 'HOU')  | (fligths$dest == 'IAH'), ]
```

- Fueron operados por United, American o Delta.
```{r echo=TRUE}
airlines<-nycflights13::airlines
fligths_carriers <- fligths[(fligths$carrier == 'UA')  | (fligths$carrier == 'AA')  | (fligths$carrier == 'DL'), ]
```

- Salieron en Verano (Julio, Agosto y Septiembre)
```{r echo=TRUE}
fligths_spring <- fligths[(fligths$month == 7)  | (fligths$month == 8)  | (fligths$month == 9), ]
```

- Arrivaron mas de dos horas tarde, pero salieron bien.
```{r echo=TRUE}
fligths_0_2 <- fligths[(fligths$dep_delay == 0)  & (fligths$arr_delay > 2), ]
```


```{r echo=TRUE}
fligths_0_6 <- fligths[(fligths$hour >= 0)  & (fligths$hour <= 6), ]
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### Ejercicios.


```{r echo=TRUE}
library(class)
library(gmodels)
data <- read.csv("http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data",header=FALSE)
data <- data[-1]
str(data)
```

Los valores correctos estan en la diagonal de la matriz, 98% de precision para unas pocas lineas de R!


+ Mejore el rendimiento utilizando una normalizacion con z-scores provista por la funcion scale() de R.


```{r echo=TRUE}
data_n <- as.data.frame(lapply(data[2:31], scale))
summary(data_n$V3)
summary(data_n$V8)
```

Los valores estan normalizados. Se verifica que la media ahora es 0.

***


```{r echo=TRUE}
data_train <- data_n[1:469, ]
data_test  <- data_n[470:569, ] 
data_train_labels <- data[1:469, 1]
data_test_labels  <- data[470:569, 1]
data_test_pred <- knn(train=data_train, test=data_test, cl=data_train_labels, k=21)
CrossTable(x=data_test_labels, y=data_test_pred, prop.chisq = FALSE)
```

Se mantiene precision de 98%

***

+ Pruebe algunos valores alternativos de k=1, 5,  11, 15, 21 y seleccione el mejor valor de k.


```{r echo=TRUE}
data_test_pred <- knn(train=data_train, test=data_test, cl=data_train_labels, k=11)
CrossTable(x=data_test_labels, y=data_test_pred, prop.chisq = FALSE)
```


para K = 11,15, 21, se mantiene la precición de 98% pero con K=11 mejora la prediccion en los casos M y ademas se usan menos vecinos.

***

+ mientras termina su merecido cafe verifique si el resultado cambia utilizando paciente elegidos aleatoriamente para el conjunto de validacion.


Calculamos un promedio para 10000 muestras aleatorias:

```{r echo=TRUE}
data_train <- data_n[1:469, ]
data_test  <- data_n[sample(nrow(data_n), 100), ]
data_train_labels <- data[1:469, 1]
data_test_labels  <- data[470:569, 1]
data_test_pred <- knn(train=data_train, test=data_test, cl=data_train_labels, k=11)
count <- 0
N <- 10000
for(i in seq(from=1, to=N, by=1)){
  pred_result <- table(data_test_labels, data_test_pred)
  count <- count + pred_result['B','B'] + pred_result['M', 'M'] 
}

average_predict <- count/N

```


Si la precisición se ve afectada, reduciendose en promedio a menos del 70%
