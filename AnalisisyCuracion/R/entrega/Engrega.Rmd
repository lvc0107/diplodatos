---
title: "Entrega"
output: html_document
---

## Ejercicios:

Visualizacion es una herramienta muy importante para la generacion de intuicion, pero
raramente uno tiene los datos en la forma necesaria. Frecuentemente se necesitara 
crear nuevas variables o simplemente reordenarlas.

Exploraremos ahora la manipulacion basica utilizando un conjunto de datos sobre los
vuelos en Nueva York en 2013.

```{r echo=TRUE}
library(nycflights13)
fligths<-nycflights13::flights
```

***
## Practico 1: Entregar un Rmd donde se encuentren todos los vuelos que:

- Que arribaron con un retraso de mas de dos horas.
```{r echo=TRUE}
fligths_delay_2 <- fligths[fligths$arr_delay > 120,]
```

- Volaron hacia Houston (IAH o HOU)
```{r echo=TRUE}
fligths_houston <- fligths[(fligths$dest == 'HOU')  | (fligths$dest == 'IAH'), ]
```

- Fueron operados por United, American o Delta.
```{r echo=TRUE}
airlines<-nycflights13::airlines
fligths_carriers <- fligths[(fligths$carrier == 'UA')  | (fligths$carrier == 'AA')  | (fligths$carrier == 'DL'), ]
```

- Salieron en Verano (Julio, Agosto y Septiembre)
```{r echo=TRUE}
fligths_spring <- fligths[(fligths$month == 7)  | (fligths$month == 8)  | (fligths$month == 9), ]
```

- Arrivaron mas de dos horas tarde, pero salieron bien.

```{r echo=TRUE}
fligths_0_2 <- fligths[(fligths$dep_delay == 0)  & (fligths$arr_delay > 120), ]
```


### Ejercicio: Mida el tiempo en una version vectorizada.

```{r}
m=10; n=10;
mymat<-replicate(m, rnorm(n)) # create matrix of normal random numbers
mydframe=data.frame(mymat) # transform into data frame
system.time(mydframe_vect <- mydframe + 10*sin(0.75*pi))
```



### Ejercicio: Clasificación de tumores.


```{r echo=TRUE}
library(class)
library(gmodels)
data <- read.csv("http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data",header=FALSE)
data <- data[-1]
str(data)
```

+ Mejore el rendimiento utilizando una normalizacion con z-scores provista por la funcion scale() de R.


```{r echo=TRUE}
data_n <- as.data.frame(lapply(data[2:31], scale))
summary(data_n$V3)
summary(data_n$V8)
```

Los valores estan normalizados. Se verifica que la media ahora es 0.

***


```{r echo=TRUE}
data_train <- data_n[1:469, ]
data_test  <- data_n[470:569, ] 
data_train_labels <- data[1:469, 1]
data_test_labels  <- data[470:569, 1]
data_test_pred <- knn(train=data_train, test=data_test, cl=data_train_labels, k=21)
CrossTable(x=data_test_labels, y=data_test_pred, prop.chisq = FALSE)
```

Se mantiene precision de 98%

***

+ Pruebe algunos valores alternativos de k=1, 5,  11, 15, 21 y seleccione el mejor valor de k.


```{r echo=TRUE}
data_test_pred <- knn(train=data_train, test=data_test, cl=data_train_labels, k=11)
CrossTable(x=data_test_labels, y=data_test_pred, prop.chisq = FALSE)
```


para K = 11,15, 21, se mantiene la precición de 98% pero con K=11 mejora la prediccion en los casos M y ademas se usan menos vecinos.

***

+ mientras termina su merecido cafe verifique si el resultado cambia utilizando paciente elegidos aleatoriamente para el conjunto de validacion.


Calculamos un promedio para 10000 muestras aleatorias:

```{r echo=TRUE}
data_train <- data_n[1:469, ]
data_test  <- data_n[sample(nrow(data_n), 100), ]
data_train_labels <- data[1:469, 1]
data_test_labels  <- data[470:569, 1]
data_test_pred <- knn(train=data_train, test=data_test, cl=data_train_labels, k=11)
count <- 0
N <- 10000
for(i in seq(from=1, to=N, by=1)){
  pred_result <- table(data_test_labels, data_test_pred)
  count <- count + pred_result['B','B'] + pred_result['M', 'M'] 
}

average_predict <- count/N

```

Si la precisición se ve afectada, reduciendose en promedio a menos del 70%

### Ejercicio k-means

- Elija un dataset clasificado de su preferencia y area (domain expertise), aplique un metodo de clustering y/o mixtura de Gaussianas en el mismo.

Elejimos trabajar con el mismo dataset del practico 1 : Flights. Mostramos clusters ploteando 2 features: dep_delay, arr_delay.


```{r echo=TRUE}
library(nycflights13)
library(ggplot2)

fligths<-nycflights13::flights
# Filtramos solo atributos numericos
flights_numeric <- Filter(is.numeric, flights)

# eliminamos NAN values por que es un requisito de kmeans
flights_numeric <- na.omit(flights_numeric)

#primeras 3 rows del nuevo data frame
head(flights_numeric, n = 3)

set.seed(76964057) #Set the seed for reproducibility
#Create K clusters
K = 3
flightsCluster <-kmeans(flights_numeric, K, centers=K) 

flightsCluster$centers #Display&nbsp;cluster centers

table(flightsCluster$cluster) #Give a count of data points in each cluster

flights_numeric$classes <- as.factor(flightsCluster$cluster)
ggplot(flights_numeric, aes(dep_delay, arr_delay, colour = classes)) + geom_point()

```


- Investigue los resultados en el meta parametro $K$ numero de cumulos e investigue posibles procesos de seleccion del mismo.

Probamos para K entre 2 y 20.

```{r echo=TRUE}
library(nycflights13)
library(ggplot2)

fligths<-nycflights13::flights
# Filtramos solo atributos numericos
flights_numeric <- Filter(is.numeric, flights)

# eliminamos NAN values por que es un requisito de kmeans
flights_numeric <- na.omit(flights_numeric)

K = 20

for(i in seq(from=2, to=K, by=1)){

  flightsCluster <-kmeans(flights_numeric, i, centers=i) 

  print(flightsCluster$centers) #Display&nbsp;cluster centers

  print(table(flightsCluster$cluster)) #Give a count of data points in each cluster

  flights_numeric$classes <- as.factor(flightsCluster$cluster)
  print(ggplot(flights_numeric, aes(dep_delay, arr_delay, colour = classes)) + geom_point())
}

```
***


- Elabore un resumen, y selecione un mejor valor segun el/los criterios aplicados, discuta el significado de los cumulos encontrados. 

Se concluye que para datos no normalizados, no se generan clusters muy nitidos. Promabos normalizando los features


- Comente la influencia de la normalizacion de los datos en los resultados del clustering.



```{r echo=TRUE}
library(nycflights13)
library(ggplot2)
fligths<-nycflights13::flights

# Filtramos solo atributos numericos
flights_numeric <- Filter(is.numeric, flights)

# Normalizamos
flights_numeric_z <- scale(flights_numeric)
# Eliminamos la columna fecha, pues tiene algun problema cuando se normaliza
flights_numeric_z <- subset( flights_numeric_z, select = -c(year) )
# eliminamos NAN values por que es un requisito de kmeans
flights_numeric_z <- na.omit(flights_numeric_z)

# Casteamos a data frame
flights_numeric_z <- as.data.frame(flights_numeric_z)
# verificamos que tenemos un dataframe
class(flights_numeric_z)

#primeras 3 rows del nuevo data frame
head(flights_numeric_z, n = 3)

set.seed(76964057) #Set the seed for reproducibility
#Create K clusters
K = 20

for(i in seq(from=2, to=K, by=1)){

  flightsCluster <-kmeans(flights_numeric_z, i, centers=i) 

  print(flightsCluster$centers) #Display&nbsp;cluster centers

  print(table(flightsCluster$cluster)) #Give a count of data points in each cluster

  flights_numeric_z$classes <- as.factor(flightsCluster$cluster)
  print(ggplot(flights_numeric_z, aes(dep_delay, arr_delay, colour = classes)) + geom_point())
}
```

***

Con features normalizados se visualizan por lo menos 1 grupo que contiene la mayoria de las observaciones hasta K=14, luego de  K=15 a 19, se distinguen mas claramente 2 grupos. 



